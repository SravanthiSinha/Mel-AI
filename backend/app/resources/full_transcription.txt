Hello and welcome back. Last week you learned about RNNs, GRUs, and LSTMs. In this week, you see how many of these ideas can be applied to NLP, to Natural Language Processing, which is one of the fields of AI that is really being revolutionized by deep learning. One of the key ideas you learn about is word embeddings, which is a way of representing words that lets your algorithms automatically understand analogies like that, man is the woman as king is the queen, and many other examples. Through these ideas of word embeddings, you'll be able to build NLP applications even with modest lead size or even with relatively small label training sets. Finally, towards the end of the week, you see how to de -bias word embeddings as to reduce undesirable gender or ethnicity or other types of bias that learning algorithms can sometimes pick up. So with that, let's get started with a discussion on word representation. So far, we've been representing words using a vocabulary of words, and our vocabulary from the previous week might be, say, 10 ,000 words. And we've been representing words using a one -hot vector. So, for example, if man is word number 5391 in this dictionary, then you represent it with a vector. with a one in position 5391. And I'm also going to use O subscript 5391 to represent this vector where O here stands for one hot. And then if woman is word number nine, eight, five, three, then you represent it with O subscript nine, eight, five, three, which just has a one in position nine, eight, five, three and zeros elsewhere. And then other words, king, queen, apple, orange would be similarly represented with one -hot vectors. One of the weaknesses of this representation is that it treats each word as a thing unto itself. and it doesn't allow an algorithm to easily generalize across words. For example, let's say you have a language model that has learned that when you see I want a glass of orange blank, well, what do you think the next word will be? Very likely to be juice. But even if the learning algorithm has learned that I want a glass of orange juice is a likely sentence, if it sees I want a glass of apple blank, as far as it knows, the relationship between apple and orange is not any closer as the relationship between any of the other words, man, woman, king, queen, and orange. And so it's not easy for the learning algorithm to generalize from knowing that orange juice is a popular thing to recognizing that apple juice might also be a popular thing or a popular phrase. And this is because the inner product between any two different one -hot vectors is zero. If you take any two vectors, say, queen and king and inner product them, the inner product is zero. If you take apple and orange and the inner product of them, the inner product is zero. And Euclidean distance between any pair of these vectors is also the same. So it just doesn't know that somehow apple and orange are much more similar than king and orange or queen and orange. So wouldn't it be nice if instead of a one -hot representation, we can instead learn a featurized representation where for each of these words, man, woman, king, queen, apple, orange, or really for every word in a dictionary, we could learn a set of features and values for each of them. So for example, each of these words might have, we want to know, what is the gender associated with each of these things. So, gender goes from minus one for male to plus one for female, then the gender associated man might be minus one, for woman might be plus one, and then if you're actually learning these things, maybe for king you get minus 0 .95, for queen plus 0 .97, and for apple and orange, you know, sort of genderless. Another feature might be, well, how royal are these things? And so, the terms, man and woman are not particularly royal, so they might have features values close to zero, whereas king and queen are highly royal, and apple and orange are not particularly royal. How about age? Well, man and woman doesn't connote much about age. Maybe man and woman implies that they're adults, but maybe neither. necessarily young not old so maybe values close to zero whereas kings and queens are always almost always adults and apple and orange might be more neutral respect to age and then another feature for you know is this a food and well man is not a food woman is not a food neither are kings and queens but apples and oranges are foods And there can be many other features as well, ranging from what is the size of this, what is the cost, is this something that is alive, is this an action, or is this a noun, or is this a verb, or is this something else, and so on. So you can imagine coming up with many features, and for the sake of illustration, let's say 300 different features, and what that does is it allows you to take this list of numbers, I've only written four here, but this could be a list of maybe 300 numbers, that then becomes a 300 dimensional vector for representing the word man. And I'm going to use the notation E subscript 5391 to denote a representation like this. And similarly, this vector, this 300 dimensional vector or 300 dimensional vector like this, I would denote E9853 to denote a 300 dimensional vector we could use to represent the word woman. And similarly, for the other examples here. Now, if you use this representation to represent the words orange and apple, then notice that the representations for orange and apple are now quite similar. Some of the features will differ because maybe the color of an orange, the color of an apple, the taste or some other features will differ. But by and large, a lot of features of apple and orange are actually the same or take on very similar values. So this increases the odds of the learning algorithm. that has figured out that orange juice is a thing to also quickly figure out that apple juice is a thing. So this allows it to generalize better across different words. So over the next few videos, we'll find a way to learn word embeddings, which is basically to learn high -dimensional feature vectors like these that gives a better representation than one -hot vectors for representing different words. The features we'll end up learning won't have a easy to interpret interpretation like that component one is gender, component two is royal, component three is Asian and so on. Exactly what they're representing will be a bit harder to figure out, but nonetheless, the featurized representations we'll learn will allow an algorithm to quickly figure out that apple and orange are more similar than say, king and orange or queen and orange. If we're able to learn a 300 -dimensional feature vector or 300 -dimensional embedding for each word, one of the popular things to do is also to take this 300 -dimensional data and embed it, say, in a two -dimensional space so that you can visualize them. And so one common algorithm for doing this is the t -SNE algorithm due to Lauren van der Maarten and Jeff Hinton. And if you look at one of these one of these representations, you find that words like man and woman tend to get grouped together, king and queen tend to get grouped together, and these are the people which tend to get grouped together, those are animals who tend to get grouped together, the fruits will tend to be close to each other, numbers like 1, 2, 3, 4 will be close to each other, and then maybe the animates objects as a whole will also tend to get grouped together. But you see plots like these sometimes on the Internet to visualize some of these 300 or higher dimensional embeddings. Maybe this gives you a sense that word embedding algorithms like these can learn similar features for concepts that feel like they should be more related, as visualized by that concept that seemed to you and me like they should be more similar, end up getting mapped to more similar feature vectors. and these representations we'll use these sort of featurized representations in maybe a 300 dimensional space these are called embeddings and the reason we call them embeddings is you can think of a 300 dimensional space and again they can't draw 300 dimensional spaces maybe it's a 3d one and what you do is you take every word like orange and you you know have a 300 dimensional feature vector so the word orange gets embedded to a point in this 300 dimensional space and the word apple gets embedded to a different point in this 300 dimensional space and of course to visualize it algorithms like t -sneed map this to much lower dimensional space you can actually plot the 2d data and look at it but that's where the term embedding comes from Word embeddings has been one of the most important ideas in NLP, in Natural Language Processing. In this video, you saw why you might want to learn or use word embeddings. In the next video, let's take a deeper look at how you'll be able to use these algorithms to build NLP algorithms.